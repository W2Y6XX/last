#!/usr/bin/env python3
"""
ç³»ç»Ÿå‹åŠ›æµ‹è¯•

è¿™ä¸ªè„šæœ¬å¯¹LangGraphå¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¿›è¡Œå…¨é¢çš„å‹åŠ›æµ‹è¯•ã€‚
åŒ…æ‹¬ï¼š
- å¹¶å‘ä»»åŠ¡å¤„ç†æµ‹è¯•
- å†…å­˜ä½¿ç”¨æµ‹è¯•
- å“åº”æ—¶é—´æµ‹è¯•
- é”™è¯¯æ¢å¤æµ‹è¯•
- é•¿æ—¶é—´è¿è¡Œæµ‹è¯•
"""

import asyncio
import logging
import time
import psutil
import statistics
from datetime import datetime, timedelta
from typing import Dict, Any, List, Tuple
import random
import json
from concurrent.futures import ThreadPoolExecutor
import threading

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥ç³»ç»Ÿç»„ä»¶
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from langgraph_multi_agent.system.integration import SystemIntegrator


class StressTestMetrics:
    """å‹åŠ›æµ‹è¯•æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self.start_time = None
        self.end_time = None
        self.task_results = []
        self.system_metrics = []
        self.error_count = 0
        self.success_count = 0
        self.response_times = []
        self.memory_usage = []
        self.cpu_usage = []
        
    def start_test(self):
        """å¼€å§‹æµ‹è¯•"""
        self.start_time = datetime.now()
        
    def end_test(self):
        """ç»“æŸæµ‹è¯•"""
        self.end_time = datetime.now()
        
    def add_task_result(self, task_id: str, success: bool, response_time: float, error: str = None):
        """æ·»åŠ ä»»åŠ¡ç»“æœ"""
        result = {
            "task_id": task_id,
            "success": success,
            "response_time": response_time,
            "timestamp": datetime.now(),
            "error": error
        }
        
        self.task_results.append(result)
        self.response_times.append(response_time)
        
        if success:
            self.success_count += 1
        else:
            self.error_count += 1
    
    def add_system_metrics(self, cpu: float, memory: float):
        """æ·»åŠ ç³»ç»ŸæŒ‡æ ‡"""
        self.system_metrics.append({
            "timestamp": datetime.now(),
            "cpu_usage": cpu,
            "memory_usage": memory
        })
        
        self.cpu_usage.append(cpu)
        self.memory_usage.append(memory)
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–æµ‹è¯•æ‘˜è¦"""
        if not self.start_time or not self.end_time:
            return {"error": "æµ‹è¯•æœªå®Œæˆ"}
        
        total_time = (self.end_time - self.start_time).total_seconds()
        total_tasks = len(self.task_results)
        
        summary = {
            "test_duration": total_time,
            "total_tasks": total_tasks,
            "successful_tasks": self.success_count,
            "failed_tasks": self.error_count,
            "success_rate": self.success_count / total_tasks if total_tasks > 0 else 0,
            "throughput": total_tasks / total_time if total_time > 0 else 0,
            "response_time": {
                "min": min(self.response_times) if self.response_times else 0,
                "max": max(self.response_times) if self.response_times else 0,
                "avg": statistics.mean(self.response_times) if self.response_times else 0,
                "median": statistics.median(self.response_times) if self.response_times else 0,
                "p95": statistics.quantiles(self.response_times, n=20)[18] if len(self.response_times) >= 20 else 0,
                "p99": statistics.quantiles(self.response_times, n=100)[98] if len(self.response_times) >= 100 else 0
            },
            "system_resources": {
                "avg_cpu": statistics.mean(self.cpu_usage) if self.cpu_usage else 0,
                "max_cpu": max(self.cpu_usage) if self.cpu_usage else 0,
                "avg_memory": statistics.mean(self.memory_usage) if self.memory_usage else 0,
                "max_memory": max(self.memory_usage) if self.memory_usage else 0
            }
        }
        
        return summary


class StressTestRunner:
    """å‹åŠ›æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, integrator: SystemIntegrator):
        self.integrator = integrator
        self.metrics = StressTestMetrics()
        self.is_monitoring = False
        self.monitor_task = None
        
    async def start_monitoring(self):
        """å¼€å§‹ç³»ç»Ÿç›‘æ§"""
        self.is_monitoring = True
        self.monitor_task = asyncio.create_task(self._monitor_system())
        
    async def stop_monitoring(self):
        """åœæ­¢ç³»ç»Ÿç›‘æ§"""
        self.is_monitoring = False
        if self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass
    
    async def _monitor_system(self):
        """ç³»ç»Ÿç›‘æ§å¾ªç¯"""
        while self.is_monitoring:
            try:
                cpu_percent = psutil.cpu_percent(interval=1)
                memory_percent = psutil.virtual_memory().percent
                
                self.metrics.add_system_metrics(cpu_percent, memory_percent)
                
                await asyncio.sleep(5)  # æ¯5ç§’ç›‘æ§ä¸€æ¬¡
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ç³»ç»Ÿç›‘æ§é”™è¯¯: {e}")
    
    async def run_concurrent_task_test(self, num_tasks: int = 50, concurrency: int = 10) -> Dict[str, Any]:
        """å¹¶å‘ä»»åŠ¡æµ‹è¯•"""
        print(f"\nğŸ”¥ å¹¶å‘ä»»åŠ¡æµ‹è¯• - {num_tasks} ä¸ªä»»åŠ¡ï¼Œå¹¶å‘åº¦ {concurrency}")
        
        self.metrics.start_test()
        await self.start_monitoring()
        
        try:
            # åˆ›å»ºä»»åŠ¡
            tasks = []
            for i in range(num_tasks):
                task_data = {
                    "task_id": f"stress_task_{i}",
                    "title": f"å‹åŠ›æµ‹è¯•ä»»åŠ¡ {i}",
                    "description": f"è¿™æ˜¯ç¬¬ {i} ä¸ªå‹åŠ›æµ‹è¯•ä»»åŠ¡",
                    "complexity": random.choice(["simple", "medium", "complex"]),
                    "priority": random.randint(1, 3),
                    "requirements": [f"å¤„ç†æ­¥éª¤ {j}" for j in range(random.randint(2, 5))]
                }
                tasks.append(task_data)
            
            # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘åº¦
            semaphore = asyncio.Semaphore(concurrency)
            
            async def execute_single_task(task_data):
                async with semaphore:
                    start_time = time.time()
                    try:
                        # åˆ›å»ºå·¥ä½œæµ
                        workflow_id = f"stress_workflow_{task_data['task_id']}"
                        await self.integrator.create_workflow(workflow_id, "simple")
                        
                        # æ‰§è¡Œä»»åŠ¡
                        result = await self.integrator.execute_workflow(workflow_id, task_data)
                        
                        response_time = time.time() - start_time
                        self.metrics.add_task_result(task_data['task_id'], True, response_time)
                        
                        return {"success": True, "result": result}
                        
                    except Exception as e:
                        response_time = time.time() - start_time
                        self.metrics.add_task_result(task_data['task_id'], False, response_time, str(e))
                        return {"success": False, "error": str(e)}
            
            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            print("â³ æ‰§è¡Œå¹¶å‘ä»»åŠ¡...")
            results = await asyncio.gather(*[execute_single_task(task) for task in tasks], return_exceptions=True)
            
            self.metrics.end_test()
            await self.stop_monitoring()
            
            # ç»Ÿè®¡ç»“æœ
            successful = sum(1 for r in results if isinstance(r, dict) and r.get("success"))
            failed = len(results) - successful
            
            print(f"âœ… å¹¶å‘æµ‹è¯•å®Œæˆ: æˆåŠŸ {successful}, å¤±è´¥ {failed}")
            
            return self.metrics.get_summary()
            
        except Exception as e:
            logger.error(f"å¹¶å‘ä»»åŠ¡æµ‹è¯•å¤±è´¥: {e}")
            await self.stop_monitoring()
            return {"error": str(e)}
    
    async def run_memory_stress_test(self, duration_minutes: int = 5) -> Dict[str, Any]:
        """å†…å­˜å‹åŠ›æµ‹è¯•"""
        print(f"\nğŸ’¾ å†…å­˜å‹åŠ›æµ‹è¯• - æŒç»­ {duration_minutes} åˆ†é’Ÿ")
        
        self.metrics = StressTestMetrics()  # é‡ç½®æŒ‡æ ‡
        self.metrics.start_test()
        await self.start_monitoring()
        
        end_time = datetime.now() + timedelta(minutes=duration_minutes)
        task_counter = 0
        
        try:
            while datetime.now() < end_time:
                # åˆ›å»ºå¤§é‡å°ä»»åŠ¡
                batch_tasks = []
                for i in range(20):  # æ¯æ‰¹20ä¸ªä»»åŠ¡
                    task_data = {
                        "task_id": f"memory_test_{task_counter}_{i}",
                        "title": f"å†…å­˜æµ‹è¯•ä»»åŠ¡ {task_counter}_{i}",
                        "description": "å†…å­˜å‹åŠ›æµ‹è¯•ä»»åŠ¡",
                        "data": "x" * random.randint(1000, 10000),  # éšæœºå¤§å°çš„æ•°æ®
                        "requirements": ["å†…å­˜å¤„ç†", "æ•°æ®å­˜å‚¨", "ç»“æœè¿”å›"]
                    }
                    batch_tasks.append(task_data)
                
                # æ‰§è¡Œæ‰¹æ¬¡ä»»åŠ¡
                for task_data in batch_tasks:
                    start_time = time.time()
                    try:
                        workflow_id = f"memory_workflow_{task_data['task_id']}"
                        await self.integrator.create_workflow(workflow_id, "simple")
                        result = await self.integrator.execute_workflow(workflow_id, task_data)
                        
                        response_time = time.time() - start_time
                        self.metrics.add_task_result(task_data['task_id'], True, response_time)
                        
                    except Exception as e:
                        response_time = time.time() - start_time
                        self.metrics.add_task_result(task_data['task_id'], False, response_time, str(e))
                
                task_counter += 1
                
                # çŸ­æš‚ä¼‘æ¯
                await asyncio.sleep(1)
                
                # æ˜¾ç¤ºè¿›åº¦
                remaining = (end_time - datetime.now()).total_seconds()
                if task_counter % 10 == 0:
                    print(f"   è¿›åº¦: å·²æ‰§è¡Œ {task_counter * 20} ä¸ªä»»åŠ¡, å‰©ä½™ {remaining:.0f} ç§’")
            
            self.metrics.end_test()
            await self.stop_monitoring()
            
            print(f"âœ… å†…å­˜å‹åŠ›æµ‹è¯•å®Œæˆ")
            
            return self.metrics.get_summary()
            
        except Exception as e:
            logger.error(f"å†…å­˜å‹åŠ›æµ‹è¯•å¤±è´¥: {e}")
            await self.stop_monitoring()
            return {"error": str(e)}
    
    async def run_response_time_test(self, num_requests: int = 100) -> Dict[str, Any]:
        """å“åº”æ—¶é—´æµ‹è¯•"""
        print(f"\nâš¡ å“åº”æ—¶é—´æµ‹è¯• - {num_requests} ä¸ªè¯·æ±‚")
        
        self.metrics = StressTestMetrics()  # é‡ç½®æŒ‡æ ‡
        self.metrics.start_test()
        await self.start_monitoring()
        
        try:
            for i in range(num_requests):
                task_data = {
                    "task_id": f"response_test_{i}",
                    "title": f"å“åº”æ—¶é—´æµ‹è¯• {i}",
                    "description": "å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•",
                    "requirements": ["å¿«é€Ÿå¤„ç†", "ç«‹å³å“åº”"]
                }
                
                start_time = time.time()
                try:
                    workflow_id = f"response_workflow_{i}"
                    await self.integrator.create_workflow(workflow_id, "simple")
                    result = await self.integrator.execute_workflow(workflow_id, task_data)
                    
                    response_time = time.time() - start_time
                    self.metrics.add_task_result(task_data['task_id'], True, response_time)
                    
                except Exception as e:
                    response_time = time.time() - start_time
                    self.metrics.add_task_result(task_data['task_id'], False, response_time, str(e))
                
                # æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 20 == 0:
                    print(f"   è¿›åº¦: {i + 1}/{num_requests}")
            
            self.metrics.end_test()
            await self.stop_monitoring()
            
            print(f"âœ… å“åº”æ—¶é—´æµ‹è¯•å®Œæˆ")
            
            return self.metrics.get_summary()
            
        except Exception as e:
            logger.error(f"å“åº”æ—¶é—´æµ‹è¯•å¤±è´¥: {e}")
            await self.stop_monitoring()
            return {"error": str(e)}
    
    async def run_error_recovery_test(self, num_tasks: int = 30) -> Dict[str, Any]:
        """é”™è¯¯æ¢å¤æµ‹è¯•"""
        print(f"\nğŸ”§ é”™è¯¯æ¢å¤æµ‹è¯• - {num_tasks} ä¸ªä»»åŠ¡ï¼ˆåŒ…å«æ•…æ„é”™è¯¯ï¼‰")
        
        self.metrics = StressTestMetrics()  # é‡ç½®æŒ‡æ ‡
        self.metrics.start_test()
        await self.start_monitoring()
        
        try:
            for i in range(num_tasks):
                # 30%çš„ä»»åŠ¡æ•…æ„åŒ…å«é”™è¯¯
                should_fail = random.random() < 0.3
                
                task_data = {
                    "task_id": f"error_test_{i}",
                    "title": f"é”™è¯¯æ¢å¤æµ‹è¯• {i}",
                    "description": "é”™è¯¯æ¢å¤èƒ½åŠ›æµ‹è¯•",
                    "should_fail": should_fail,  # æ ‡è®°æ˜¯å¦åº”è¯¥å¤±è´¥
                    "requirements": ["å¤„ç†è¾“å…¥", "ç”Ÿæˆè¾“å‡º", "é”™è¯¯å¤„ç†"]
                }
                
                start_time = time.time()
                try:
                    workflow_id = f"error_workflow_{i}"
                    await self.integrator.create_workflow(workflow_id, "simple")
                    
                    # å¦‚æœæ ‡è®°ä¸ºåº”è¯¥å¤±è´¥ï¼Œåˆ™ä¼ å…¥æ— æ•ˆæ•°æ®
                    if should_fail:
                        task_data["invalid_data"] = None
                        task_data["requirements"] = None
                    
                    result = await self.integrator.execute_workflow(workflow_id, task_data)
                    
                    response_time = time.time() - start_time
                    # å¦‚æœä»»åŠ¡åº”è¯¥å¤±è´¥ä½†æˆåŠŸäº†ï¼Œè¿™ä¹Ÿç®—æ˜¯ä¸€ç§æˆåŠŸï¼ˆç³»ç»Ÿå¤„ç†äº†é”™è¯¯ï¼‰
                    self.metrics.add_task_result(task_data['task_id'], True, response_time)
                    
                except Exception as e:
                    response_time = time.time() - start_time
                    # å¦‚æœä»»åŠ¡åº”è¯¥å¤±è´¥ä¸”ç¡®å®å¤±è´¥äº†ï¼Œè¿™æ˜¯é¢„æœŸçš„
                    success = should_fail  # é¢„æœŸå¤±è´¥çš„ä»»åŠ¡å¤±è´¥äº†ç®—æˆåŠŸ
                    self.metrics.add_task_result(task_data['task_id'], success, response_time, str(e))
                
                # æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 10 == 0:
                    print(f"   è¿›åº¦: {i + 1}/{num_tasks}")
            
            self.metrics.end_test()
            await self.stop_monitoring()
            
            print(f"âœ… é”™è¯¯æ¢å¤æµ‹è¯•å®Œæˆ")
            
            return self.metrics.get_summary()
            
        except Exception as e:
            logger.error(f"é”™è¯¯æ¢å¤æµ‹è¯•å¤±è´¥: {e}")
            await self.stop_monitoring()
            return {"error": str(e)}


async def run_comprehensive_stress_test():
    """è¿è¡Œç»¼åˆå‹åŠ›æµ‹è¯•"""
    
    print("=" * 80)
    print("LangGraphå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ - ç»¼åˆå‹åŠ›æµ‹è¯•")
    print("=" * 80)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    print("\nğŸš€ åˆå§‹åŒ–æµ‹è¯•ç³»ç»Ÿ...")
    
    config = {
        "checkpoint_storage": "memory",
        "enable_metrics": True,
        "enable_tracing": False,  # å…³é—­è¿½è¸ªä»¥å‡å°‘å¼€é”€
        "optimization_level": "aggressive",
        "performance": {
            "max_cache_size": 20000,
            "enable_auto_optimization": True,
            "max_workers": 8,
            "execution_mode": "adaptive",
            "enable_auto_scaling": True
        }
    }
    
    integrator = SystemIntegrator(config)
    
    try:
        success = await integrator.initialize_system()
        if not success:
            print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return
        
        print("âœ… æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
        test_runner = StressTestRunner(integrator)
        
        # æ”¶é›†æ‰€æœ‰æµ‹è¯•ç»“æœ
        all_results = {}
        
        # 1. å¹¶å‘ä»»åŠ¡æµ‹è¯•
        print("\n" + "="*50)
        print("æµ‹è¯• 1/4: å¹¶å‘ä»»åŠ¡å¤„ç†èƒ½åŠ›")
        print("="*50)
        
        concurrent_result = await test_runner.run_concurrent_task_test(
            num_tasks=100,  # 100ä¸ªä»»åŠ¡
            concurrency=20  # 20ä¸ªå¹¶å‘
        )
        all_results["concurrent_tasks"] = concurrent_result
        
        if "error" not in concurrent_result:
            print(f"   ååé‡: {concurrent_result['throughput']:.2f} ä»»åŠ¡/ç§’")
            print(f"   æˆåŠŸç‡: {concurrent_result['success_rate']:.2%}")
            print(f"   å¹³å‡å“åº”æ—¶é—´: {concurrent_result['response_time']['avg']:.3f} ç§’")
            print(f"   P95å“åº”æ—¶é—´: {concurrent_result['response_time']['p95']:.3f} ç§’")
        
        # çŸ­æš‚ä¼‘æ¯
        await asyncio.sleep(5)
        
        # 2. å†…å­˜å‹åŠ›æµ‹è¯•
        print("\n" + "="*50)
        print("æµ‹è¯• 2/4: å†…å­˜ä½¿ç”¨å‹åŠ›æµ‹è¯•")
        print("="*50)
        
        memory_result = await test_runner.run_memory_stress_test(duration_minutes=3)
        all_results["memory_stress"] = memory_result
        
        if "error" not in memory_result:
            print(f"   å¤„ç†ä»»åŠ¡æ•°: {memory_result['total_tasks']}")
            print(f"   å¹³å‡å†…å­˜ä½¿ç”¨: {memory_result['system_resources']['avg_memory']:.1f}%")
            print(f"   å³°å€¼å†…å­˜ä½¿ç”¨: {memory_result['system_resources']['max_memory']:.1f}%")
            print(f"   å¹³å‡CPUä½¿ç”¨: {memory_result['system_resources']['avg_cpu']:.1f}%")
        
        # çŸ­æš‚ä¼‘æ¯
        await asyncio.sleep(5)
        
        # 3. å“åº”æ—¶é—´æµ‹è¯•
        print("\n" + "="*50)
        print("æµ‹è¯• 3/4: å“åº”æ—¶é—´åŸºå‡†æµ‹è¯•")
        print("="*50)
        
        response_result = await test_runner.run_response_time_test(num_requests=200)
        all_results["response_time"] = response_result
        
        if "error" not in response_result:
            print(f"   æœ€å°å“åº”æ—¶é—´: {response_result['response_time']['min']:.3f} ç§’")
            print(f"   æœ€å¤§å“åº”æ—¶é—´: {response_result['response_time']['max']:.3f} ç§’")
            print(f"   å¹³å‡å“åº”æ—¶é—´: {response_result['response_time']['avg']:.3f} ç§’")
            print(f"   ä¸­ä½æ•°å“åº”æ—¶é—´: {response_result['response_time']['median']:.3f} ç§’")
        
        # çŸ­æš‚ä¼‘æ¯
        await asyncio.sleep(5)
        
        # 4. é”™è¯¯æ¢å¤æµ‹è¯•
        print("\n" + "="*50)
        print("æµ‹è¯• 4/4: é”™è¯¯æ¢å¤èƒ½åŠ›æµ‹è¯•")
        print("="*50)
        
        error_result = await test_runner.run_error_recovery_test(num_tasks=50)
        all_results["error_recovery"] = error_result
        
        if "error" not in error_result:
            print(f"   é”™è¯¯å¤„ç†æˆåŠŸç‡: {error_result['success_rate']:.2%}")
            print(f"   å¹³å‡æ¢å¤æ—¶é—´: {error_result['response_time']['avg']:.3f} ç§’")
        
        # 5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        print("\n" + "="*80)
        print("ç»¼åˆæµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        
        generate_comprehensive_report(all_results)
        
        # 6. ç³»ç»Ÿä¼˜åŒ–å»ºè®®
        print("\n" + "="*50)
        print("ç³»ç»Ÿä¼˜åŒ–å»ºè®®")
        print("="*50)
        
        recommendations = integrator.get_performance_recommendations()
        if isinstance(recommendations, dict) and "error" not in recommendations:
            for category, suggestions in recommendations.items():
                if suggestions and isinstance(suggestions, list):
                    print(f"\n{category}:")
                    for suggestion in suggestions:
                        print(f"  ğŸ’¡ {suggestion}")
        
        # 7. æ‰§è¡Œç³»ç»Ÿä¼˜åŒ–
        print("\nä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½...")
        optimization_result = await integrator.optimize_system_performance()
        
        if "error" not in optimization_result:
            print(f"âœ… ç³»ç»Ÿä¼˜åŒ–å®Œæˆ")
            print(f"   åº”ç”¨ä¼˜åŒ–ç­–ç•¥: {optimization_result.get('optimization_results', 0)} ä¸ª")
            print(f"   æ€§èƒ½æå‡: {optimization_result.get('total_improvement', 0):.1f}%")
        
    except Exception as e:
        print(f"âŒ å‹åŠ›æµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"å‹åŠ›æµ‹è¯•é”™è¯¯: {e}")
    
    finally:
        # æ¸…ç†èµ„æº
        print("\nğŸ§¹ æ¸…ç†æµ‹è¯•èµ„æº...")
        try:
            await integrator.shutdown_system()
            print("âœ… ç³»ç»Ÿå…³é—­å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸  ç³»ç»Ÿå…³é—­æ—¶å‡ºç°è­¦å‘Š: {e}")
    
    print("\n" + "="*80)
    print("ç»¼åˆå‹åŠ›æµ‹è¯•å®Œæˆ")
    print("="*80)


def generate_comprehensive_report(results: Dict[str, Any]):
    """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
    
    print("\nğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦:")
    print("-" * 60)
    
    # å¹¶å‘æµ‹è¯•ç»“æœ
    if "concurrent_tasks" in results and "error" not in results["concurrent_tasks"]:
        concurrent = results["concurrent_tasks"]
        print(f"å¹¶å‘ä»»åŠ¡æµ‹è¯•:")
        print(f"  â€¢ æ€»ä»»åŠ¡æ•°: {concurrent['total_tasks']}")
        print(f"  â€¢ æˆåŠŸç‡: {concurrent['success_rate']:.2%}")
        print(f"  â€¢ ååé‡: {concurrent['throughput']:.2f} ä»»åŠ¡/ç§’")
        print(f"  â€¢ å¹³å‡å“åº”æ—¶é—´: {concurrent['response_time']['avg']:.3f} ç§’")
        print(f"  â€¢ P95å“åº”æ—¶é—´: {concurrent['response_time']['p95']:.3f} ç§’")
    
    # å†…å­˜æµ‹è¯•ç»“æœ
    if "memory_stress" in results and "error" not in results["memory_stress"]:
        memory = results["memory_stress"]
        print(f"\nå†…å­˜å‹åŠ›æµ‹è¯•:")
        print(f"  â€¢ æµ‹è¯•æ—¶é•¿: {memory['test_duration']:.1f} ç§’")
        print(f"  â€¢ å¤„ç†ä»»åŠ¡: {memory['total_tasks']} ä¸ª")
        print(f"  â€¢ å¹³å‡å†…å­˜ä½¿ç”¨: {memory['system_resources']['avg_memory']:.1f}%")
        print(f"  â€¢ å³°å€¼å†…å­˜ä½¿ç”¨: {memory['system_resources']['max_memory']:.1f}%")
        print(f"  â€¢ å¹³å‡CPUä½¿ç”¨: {memory['system_resources']['avg_cpu']:.1f}%")
    
    # å“åº”æ—¶é—´æµ‹è¯•ç»“æœ
    if "response_time" in results and "error" not in results["response_time"]:
        response = results["response_time"]
        print(f"\nå“åº”æ—¶é—´æµ‹è¯•:")
        print(f"  â€¢ è¯·æ±‚æ€»æ•°: {response['total_tasks']}")
        print(f"  â€¢ æœ€å°å“åº”æ—¶é—´: {response['response_time']['min']:.3f} ç§’")
        print(f"  â€¢ æœ€å¤§å“åº”æ—¶é—´: {response['response_time']['max']:.3f} ç§’")
        print(f"  â€¢ å¹³å‡å“åº”æ—¶é—´: {response['response_time']['avg']:.3f} ç§’")
        print(f"  â€¢ ä¸­ä½æ•°å“åº”æ—¶é—´: {response['response_time']['median']:.3f} ç§’")
        print(f"  â€¢ P99å“åº”æ—¶é—´: {response['response_time']['p99']:.3f} ç§’")
    
    # é”™è¯¯æ¢å¤æµ‹è¯•ç»“æœ
    if "error_recovery" in results and "error" not in results["error_recovery"]:
        error_recovery = results["error_recovery"]
        print(f"\né”™è¯¯æ¢å¤æµ‹è¯•:")
        print(f"  â€¢ æµ‹è¯•ä»»åŠ¡æ•°: {error_recovery['total_tasks']}")
        print(f"  â€¢ é”™è¯¯å¤„ç†æˆåŠŸç‡: {error_recovery['success_rate']:.2%}")
        print(f"  â€¢ å¹³å‡æ¢å¤æ—¶é—´: {error_recovery['response_time']['avg']:.3f} ç§’")
    
    # æ•´ä½“è¯„ä¼°
    print(f"\nğŸ¯ æ•´ä½“æ€§èƒ½è¯„ä¼°:")
    print("-" * 30)
    
    # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆç®€åŒ–è¯„åˆ†ç³»ç»Ÿï¼‰
    score = 0
    max_score = 0
    
    if "concurrent_tasks" in results and "error" not in results["concurrent_tasks"]:
        concurrent = results["concurrent_tasks"]
        # æˆåŠŸç‡æƒé‡40%
        score += concurrent['success_rate'] * 40
        max_score += 40
        
        # å“åº”æ—¶é—´æƒé‡30%ï¼ˆå“åº”æ—¶é—´è¶ŠçŸ­å¾—åˆ†è¶Šé«˜ï¼‰
        if concurrent['response_time']['avg'] < 1.0:
            score += 30
        elif concurrent['response_time']['avg'] < 2.0:
            score += 20
        elif concurrent['response_time']['avg'] < 5.0:
            score += 10
        max_score += 30
    
    if "error_recovery" in results and "error" not in results["error_recovery"]:
        error_recovery = results["error_recovery"]
        # é”™è¯¯æ¢å¤æƒé‡30%
        score += error_recovery['success_rate'] * 30
        max_score += 30
    
    if max_score > 0:
        final_score = (score / max_score) * 100
        
        if final_score >= 90:
            grade = "ä¼˜ç§€ ğŸ†"
        elif final_score >= 80:
            grade = "è‰¯å¥½ ğŸ‘"
        elif final_score >= 70:
            grade = "ä¸€èˆ¬ ğŸ‘Œ"
        else:
            grade = "éœ€è¦æ”¹è¿› âš ï¸"
        
        print(f"ç»¼åˆå¾—åˆ†: {final_score:.1f}/100 - {grade}")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"stress_test_report_{timestamp}.json"
    
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, default=str, ensure_ascii=False)
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        asyncio.run(run_comprehensive_stress_test())
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"æµ‹è¯•ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        logger.error(f"ä¸»ç¨‹åºé”™è¯¯: {e}")


if __name__ == "__main__":
    main()