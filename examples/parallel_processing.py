#!/usr/bin/env python3
"""
å¹¶è¡Œå¤„ç†ç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¿›è¡Œå¹¶è¡Œä»»åŠ¡å¤„ç†ã€‚
åŒ…æ‹¬ï¼š
- ä»»åŠ¡åˆ†è§£
- å¹¶è¡Œæ‰§è¡Œ
- ç»“æœèšåˆ
- æ€§èƒ½å¯¹æ¯”
"""

import asyncio
import logging
import time
from datetime import datetime
from typing import Dict, Any, List
import random

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥ç³»ç»Ÿç»„ä»¶
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langgraph_multi_agent.system.integration import SystemIntegrator


def generate_parallel_tasks() -> List[Dict[str, Any]]:
    """ç”Ÿæˆå¹¶è¡Œå¤„ç†ä»»åŠ¡"""
    
    task_types = [
        "æ–‡æœ¬å¤„ç†",
        "æ•°æ®è®¡ç®—", 
        "å›¾åƒåˆ†æ",
        "æ–‡æ¡£ç”Ÿæˆ",
        "æ•°æ®éªŒè¯"
    ]
    
    tasks = []
    for i in range(10):  # ç”Ÿæˆ10ä¸ªä»»åŠ¡
        task = {
            "task_id": f"parallel_task_{i+1}",
            "task_type": random.choice(task_types),
            "title": f"å¹¶è¡Œä»»åŠ¡ {i+1}",
            "description": f"è¿™æ˜¯ç¬¬ {i+1} ä¸ªå¹¶è¡Œå¤„ç†ä»»åŠ¡",
            "complexity": random.choice(["simple", "medium", "complex"]),
            "estimated_time": random.randint(5, 30),  # é¢„ä¼°å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
            "data_size": random.randint(100, 1000),   # æ•°æ®å¤§å°ï¼ˆKBï¼‰
            "priority": random.randint(1, 3),
            "dependencies": [],  # ç®€åŒ–ç¤ºä¾‹ï¼Œæ— ä¾èµ–å…³ç³»
            "processing_requirements": {
                "cpu_intensive": random.choice([True, False]),
                "memory_intensive": random.choice([True, False]),
                "io_intensive": random.choice([True, False])
            }
        }
        tasks.append(task)
    
    return tasks


async def simulate_task_processing(task: Dict[str, Any]) -> Dict[str, Any]:
    """æ¨¡æ‹Ÿä»»åŠ¡å¤„ç†"""
    
    start_time = time.time()
    
    # æ ¹æ®ä»»åŠ¡å¤æ‚åº¦æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    complexity_time = {
        "simple": random.uniform(1, 3),
        "medium": random.uniform(3, 8),
        "complex": random.uniform(8, 15)
    }
    
    processing_time = complexity_time.get(task["complexity"], 5)
    await asyncio.sleep(processing_time)
    
    end_time = time.time()
    actual_time = end_time - start_time
    
    # æ¨¡æ‹Ÿå¤„ç†ç»“æœ
    result = {
        "task_id": task["task_id"],
        "status": "completed",
        "actual_processing_time": actual_time,
        "estimated_time": task["estimated_time"],
        "efficiency": task["estimated_time"] / actual_time if actual_time > 0 else 1.0,
        "output_data": {
            "processed_items": random.randint(50, 200),
            "success_rate": random.uniform(0.85, 0.99),
            "quality_score": random.uniform(0.8, 0.95)
        },
        "resource_usage": {
            "cpu_usage": random.uniform(0.2, 0.8),
            "memory_usage": random.uniform(0.1, 0.6),
            "io_operations": random.randint(10, 100)
        }
    }
    
    return result


async def parallel_processing_example():
    """å¹¶è¡Œå¤„ç†ç¤ºä¾‹"""
    
    print("=" * 70)
    print("LangGraphå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ - å¹¶è¡Œå¤„ç†ç¤ºä¾‹")
    print("=" * 70)
    
    # 1. ç”Ÿæˆå¹¶è¡Œä»»åŠ¡
    print("\n1. ç”Ÿæˆå¹¶è¡Œå¤„ç†ä»»åŠ¡...")
    
    parallel_tasks = generate_parallel_tasks()
    print(f"âœ… ç”Ÿæˆ {len(parallel_tasks)} ä¸ªå¹¶è¡Œä»»åŠ¡")
    
    # æ˜¾ç¤ºä»»åŠ¡æ¦‚è§ˆ
    task_summary = {}
    for task in parallel_tasks:
        task_type = task["task_type"]
        task_summary[task_type] = task_summary.get(task_type, 0) + 1
    
    print("ä»»åŠ¡ç±»å‹åˆ†å¸ƒ:")
    for task_type, count in task_summary.items():
        print(f"  â€¢ {task_type}: {count} ä¸ª")
    
    # 2. åˆå§‹åŒ–ç³»ç»Ÿ
    print("\n2. åˆå§‹åŒ–å¹¶è¡Œå¤„ç†ç³»ç»Ÿ...")
    
    config = {
        "checkpoint_storage": "memory",
        "enable_metrics": True,
        "enable_tracing": True,
        "optimization_level": "aggressive",  # ä½¿ç”¨æ¿€è¿›ä¼˜åŒ–
        "performance": {
            "max_cache_size": 10000,
            "enable_auto_optimization": True,
            "max_workers": 8,  # å¢åŠ å·¥ä½œçº¿ç¨‹
            "execution_mode": "adaptive",
            "enable_auto_scaling": True
        }
    }
    
    integrator = SystemIntegrator(config)
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        success = await integrator.initialize_system()
        if not success:
            print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return
        
        print("âœ… å¹¶è¡Œå¤„ç†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        
        # 3. åˆ›å»ºå¹¶è¡Œå·¥ä½œæµ
        print("\n3. åˆ›å»ºå¹¶è¡Œå·¥ä½œæµ...")
        
        workflow_id = f"parallel_workflow_{int(datetime.now().timestamp())}"
        workflow = await integrator.create_workflow(
            workflow_id=workflow_id,
            template_name="parallel",  # ä½¿ç”¨å¹¶è¡Œæ¨¡æ¿
            custom_config={
                "timeout_seconds": 300,
                "max_iterations": 50,
                "execution_mode": "parallel",
                "max_concurrent_tasks": 5
            }
        )
        
        print(f"âœ… å¹¶è¡Œå·¥ä½œæµåˆ›å»ºæˆåŠŸ: {workflow_id}")
        
        # 4. é¡ºåºå¤„ç†åŸºå‡†æµ‹è¯•
        print("\n4. é¡ºåºå¤„ç†åŸºå‡†æµ‹è¯•...")
        print("â³ æ‰§è¡Œé¡ºåºå¤„ç†ï¼ˆç”¨äºæ€§èƒ½å¯¹æ¯”ï¼‰...")
        
        sequential_start = time.time()
        sequential_results = []
        
        for i, task in enumerate(parallel_tasks[:5], 1):  # åªå¤„ç†å‰5ä¸ªä»»åŠ¡ä½œä¸ºåŸºå‡†
            print(f"   å¤„ç†ä»»åŠ¡ {i}/5: {task['title']}")
            result = await simulate_task_processing(task)
            sequential_results.append(result)
        
        sequential_time = time.time() - sequential_start
        
        print(f"âœ… é¡ºåºå¤„ç†å®Œæˆï¼Œè€—æ—¶: {sequential_time:.2f}ç§’")
        
        # 5. å¹¶è¡Œå¤„ç†æµ‹è¯•
        print("\n5. å¹¶è¡Œå¤„ç†æµ‹è¯•...")
        print("â³ æ‰§è¡Œå¹¶è¡Œå¤„ç†...")
        
        parallel_start = time.time()
        
        # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
        parallel_coroutines = []
        for task in parallel_tasks:
            parallel_coroutines.append(simulate_task_processing(task))
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        parallel_results = await asyncio.gather(*parallel_coroutines, return_exceptions=True)
        
        parallel_time = time.time() - parallel_start
        
        # è¿‡æ»¤å¼‚å¸¸ç»“æœ
        successful_results = [r for r in parallel_results if not isinstance(r, Exception)]
        failed_results = [r for r in parallel_results if isinstance(r, Exception)]
        
        print(f"âœ… å¹¶è¡Œå¤„ç†å®Œæˆï¼Œè€—æ—¶: {parallel_time:.2f}ç§’")
        print(f"   æˆåŠŸä»»åŠ¡: {len(successful_results)} ä¸ª")
        print(f"   å¤±è´¥ä»»åŠ¡: {len(failed_results)} ä¸ª")
        
        # 6. æ€§èƒ½å¯¹æ¯”åˆ†æ
        print("\n6. æ€§èƒ½å¯¹æ¯”åˆ†æ:")
        print("=" * 50)
        
        # è®¡ç®—æ€§èƒ½æå‡
        if sequential_time > 0:
            speedup = sequential_time / parallel_time
            efficiency = speedup / len(parallel_tasks)
            
            print(f"é¡ºåºå¤„ç†æ—¶é—´: {sequential_time:.2f}ç§’ (5ä¸ªä»»åŠ¡)")
            print(f"å¹¶è¡Œå¤„ç†æ—¶é—´: {parallel_time:.2f}ç§’ ({len(parallel_tasks)}ä¸ªä»»åŠ¡)")
            print(f"ç†è®ºåŠ é€Ÿæ¯”: {speedup:.2f}x")
            print(f"å¹¶è¡Œæ•ˆç‡: {efficiency:.2%}")
        
        # 7. è¯¦ç»†ç»“æœåˆ†æ
        print("\n7. è¯¦ç»†ç»“æœåˆ†æ:")
        print("-" * 50)
        
        if successful_results:
            # ç»Ÿè®¡åˆ†æ
            total_processing_time = sum(r["actual_processing_time"] for r in successful_results)
            avg_processing_time = total_processing_time / len(successful_results)
            avg_efficiency = sum(r["efficiency"] for r in successful_results) / len(successful_results)
            avg_success_rate = sum(r["output_data"]["success_rate"] for r in successful_results) / len(successful_results)
            avg_quality_score = sum(r["output_data"]["quality_score"] for r in successful_results) / len(successful_results)
            
            print(f"å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.2f}ç§’")
            print(f"å¹³å‡æ•ˆç‡: {avg_efficiency:.2f}")
            print(f"å¹³å‡æˆåŠŸç‡: {avg_success_rate:.2%}")
            print(f"å¹³å‡è´¨é‡åˆ†æ•°: {avg_quality_score:.2%}")
            
            # èµ„æºä½¿ç”¨ç»Ÿè®¡
            avg_cpu = sum(r["resource_usage"]["cpu_usage"] for r in successful_results) / len(successful_results)
            avg_memory = sum(r["resource_usage"]["memory_usage"] for r in successful_results) / len(successful_results)
            total_io = sum(r["resource_usage"]["io_operations"] for r in successful_results)
            
            print(f"\nèµ„æºä½¿ç”¨æƒ…å†µ:")
            print(f"  å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.2%}")
            print(f"  å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {avg_memory:.2%}")
            print(f"  æ€»I/Oæ“ä½œæ•°: {total_io}")
        
        # 8. ç³»ç»Ÿæ€§èƒ½ç›‘æ§
        print("\n8. ç³»ç»Ÿæ€§èƒ½ç›‘æ§:")
        print("-" * 50)
        
        status = await integrator.get_system_status()
        
        if "system_performance" in status:
            perf = status["system_performance"]
            
            # å¹¶å‘æ‰§è¡Œå™¨ç»Ÿè®¡
            if "concurrent_executor" in perf:
                exec_stats = perf["concurrent_executor"]
                stats = exec_stats.get("stats", {})
                
                print("å¹¶å‘æ‰§è¡Œå™¨ç»Ÿè®¡:")
                print(f"  æäº¤ä»»åŠ¡: {stats.get('submitted', 0)} ä¸ª")
                print(f"  å®Œæˆä»»åŠ¡: {stats.get('completed', 0)} ä¸ª")
                print(f"  å¤±è´¥ä»»åŠ¡: {stats.get('failed', 0)} ä¸ª")
                print(f"  å½“å‰è´Ÿè½½: {exec_stats.get('current_load', 0):.2%}")
                print(f"  å·¥ä½œçº¿ç¨‹: {exec_stats.get('worker_threads', 0)} ä¸ª")
            
            # ç¼“å­˜æ€§èƒ½
            if "cache" in perf:
                cache_stats = perf["cache"]["global_stats"]
                print(f"\nç¼“å­˜æ€§èƒ½:")
                print(f"  å‘½ä¸­ç‡: {cache_stats.get('hit_rate', 0):.2%}")
                print(f"  ç¼“å­˜å¤§å°: {cache_stats.get('total_size', 0)} é¡¹")
        
        # 9. å¹¶å‘æ‰§è¡Œå™¨ä¼˜åŒ–
        print("\n9. å¹¶å‘æ‰§è¡Œå™¨ä¼˜åŒ–...")
        
        concurrent_executor = integrator.get_concurrent_executor()
        if concurrent_executor:
            # è·å–æ€§èƒ½æ‘˜è¦
            perf_summary = concurrent_executor.get_performance_summary()
            
            print("å¹¶å‘æ‰§è¡Œæ€§èƒ½æ‘˜è¦:")
            print(f"  æ€»ä»»åŠ¡æ•°: {perf_summary.get('total_tasks', 0)}")
            print(f"  æˆåŠŸç‡: {perf_summary.get('success_rate', 0):.2%}")
            print(f"  å¹³å‡æ‰§è¡Œæ—¶é—´: {perf_summary.get('avg_execution_time', 0):.3f}ç§’")
            print(f"  æœ€å°æ‰§è¡Œæ—¶é—´: {perf_summary.get('min_execution_time', 0):.3f}ç§’")
            print(f"  æœ€å¤§æ‰§è¡Œæ—¶é—´: {perf_summary.get('max_execution_time', 0):.3f}ç§’")
            print(f"  é˜Ÿåˆ—ç§¯å‹: {perf_summary.get('queue_backlog', 0)} ä¸ª")
            
            # å°è¯•ä¼˜åŒ–
            optimized = await concurrent_executor.adjust_concurrency_level()
            if optimized:
                print("âœ… å¹¶å‘çº§åˆ«å·²ä¼˜åŒ–")
            else:
                print("â„¹ï¸  å½“å‰å¹¶å‘çº§åˆ«å·²æ˜¯æœ€ä¼˜")
        
        # 10. å¥åº·æ£€æŸ¥å’Œå»ºè®®
        print("\n10. ç³»ç»Ÿå¥åº·æ£€æŸ¥:")
        print("-" * 50)
        
        health = await integrator.system_health_check()
        print(f"æ•´ä½“å¥åº·çŠ¶æ€: {health['overall']}")
        
        if health.get("issues"):
            print("å‘ç°çš„é—®é¢˜:")
            for issue in health["issues"]:
                print(f"  âš ï¸  {issue}")
        
        # ä¼˜åŒ–å»ºè®®
        recommendations = integrator.get_performance_recommendations()
        
        if isinstance(recommendations, dict) and "error" not in recommendations:
            print("\nä¼˜åŒ–å»ºè®®:")
            for category, suggestions in recommendations.items():
                if suggestions and isinstance(suggestions, list):
                    print(f"{category}:")
                    for suggestion in suggestions:
                        print(f"  ğŸ’¡ {suggestion}")
        
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        logger.error(f"å¹¶è¡Œå¤„ç†ç¤ºä¾‹é”™è¯¯: {e}")
    
    finally:
        # 11. æ¸…ç†èµ„æº
        print("\n11. æ¸…ç†èµ„æº...")
        
        try:
            await integrator.shutdown_system()
            print("âœ… ç³»ç»Ÿå…³é—­å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸  ç³»ç»Ÿå…³é—­æ—¶å‡ºç°è­¦å‘Š: {e}")
    
    print("\n" + "=" * 70)
    print("å¹¶è¡Œå¤„ç†ç¤ºä¾‹å®Œæˆ")
    print("=" * 70)


def main():
    """ä¸»å‡½æ•°"""
    try:
        asyncio.run(parallel_processing_example())
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        logger.error(f"ä¸»ç¨‹åºé”™è¯¯: {e}")


if __name__ == "__main__":
    main()